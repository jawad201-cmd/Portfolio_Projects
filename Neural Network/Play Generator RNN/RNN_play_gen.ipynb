{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8607af8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\miniconda3\\envs\\tf-cpu\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\miniconda3\\envs\\tf-cpu\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.6 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1372f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = keras.utils.get_file(\"shakespeare.txt\", \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a6feb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 charachters\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, \"rb\").read().decode(encoding=\"utf-8\")\n",
    "print('Length of text: {} charachters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e15479df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d0306",
   "metadata": {},
   "source": [
    "ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57f89398",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))\n",
    "\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "def text_to_int(text):\n",
    "    return np.array([char2idx[c] for c in text])\n",
    "\n",
    "text_as_int = text_to_int(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34de54d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: First Citizen\n",
      "Encoded: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "print(\"Text:\", text[:13])\n",
    "print(\"Encoded:\", text_to_int(text[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e45cb7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen\n"
     ]
    }
   ],
   "source": [
    "def int_to_text(ints):\n",
    "    try:\n",
    "        ints = ints.numpy()\n",
    "    except:\n",
    "        pass\n",
    "    return \"\".join(idx2char[ints])\n",
    "\n",
    "print(int_to_text(text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9868484",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "example_per_epoch = len(text)//(seq_length + 1)\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70434fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fca161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc3d27dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n",
      "\n",
      "OUTPUT\n",
      "irst Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You \n",
      "\n",
      "\n",
      "EXAMPLE\n",
      "\n",
      "INPUT\n",
      "are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you \n",
      "\n",
      "OUTPUT\n",
      "re all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you k\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(2):\n",
    "    print(\"\\n\\nEXAMPLE\\n\")\n",
    "    print(\"INPUT\")\n",
    "    print(int_to_text(x))\n",
    "    print(\"\\nOUTPUT\")\n",
    "    print(int_to_text(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06c75885",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 1024\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63cbd84",
   "metadata": {},
   "source": [
    "Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34a00412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,246,976</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,625</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m16,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │     \u001b[38;5;34m5,246,976\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)         │        \u001b[38;5;34m66,625\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,330,241</span> (20.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,330,241\u001b[0m (20.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,330,241</span> (20.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,330,241\u001b[0m (20.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    inputs = tf.keras.Input(batch_shape=(batch_size, None), dtype=tf.int32)\n",
    "    x = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)(inputs)\n",
    "    x = tf.keras.layers.LSTM(\n",
    "        rnn_units,\n",
    "        return_sequences=True,\n",
    "        stateful=True,\n",
    "        recurrent_initializer=\"glorot_uniform\"\n",
    "    )(x)\n",
    "    outputs = tf.keras.layers.Dense(vocab_size)(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af482c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in data.take(1):\n",
    "    example_batch_prediction = model(input_example_batch)\n",
    "    print(example_batch_prediction.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f4db957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "tf.Tensor(\n",
      "[[[-4.61240811e-03  1.63966487e-03 -1.05109706e-03 ...  2.60368688e-05\n",
      "    4.04567830e-03 -2.53483769e-04]\n",
      "  [-3.94372316e-03  6.34742249e-03 -2.35980679e-03 ...  4.11759689e-03\n",
      "    3.92765878e-03  2.69060908e-03]\n",
      "  [-5.00849215e-04  7.04597635e-03 -2.49842973e-03 ...  3.68200848e-03\n",
      "    6.24716165e-04  1.85573660e-03]\n",
      "  ...\n",
      "  [ 6.15436584e-05 -2.22764982e-04 -2.26923823e-03 ...  3.25377937e-03\n",
      "   -1.63132045e-03 -2.16826261e-03]\n",
      "  [ 4.54987725e-03  2.57715047e-03 -9.48888250e-04 ...  4.38893773e-03\n",
      "   -4.46687220e-03 -3.32914805e-03]\n",
      "  [ 1.37498137e-04  4.31576325e-03 -8.98921979e-04 ...  4.00550663e-03\n",
      "    2.79717147e-04 -2.84965639e-03]]\n",
      "\n",
      " [[-3.62777081e-03 -1.49623584e-03 -6.32101484e-03 ... -2.87026842e-03\n",
      "    2.02416000e-03 -2.92362133e-03]\n",
      "  [-1.46306003e-03  1.03005383e-03 -5.21266740e-03 ... -3.24819470e-04\n",
      "   -1.94050046e-03 -2.40783719e-03]\n",
      "  [ 3.05549521e-03 -3.07170581e-03 -8.23425595e-03 ... -2.71718367e-03\n",
      "   -1.09741138e-03  2.33151019e-04]\n",
      "  ...\n",
      "  [ 1.82811369e-03  3.02727940e-03  7.83304044e-04 ... -3.01078893e-04\n",
      "   -5.40013518e-03  5.92391379e-03]\n",
      "  [ 6.79166056e-03  7.48375617e-03  6.31767558e-03 ... -3.24054901e-03\n",
      "   -5.37749846e-03  8.51308368e-03]\n",
      "  [ 7.40417652e-03  4.83496860e-03  3.05351382e-03 ... -5.51487086e-04\n",
      "   -7.61110894e-03  4.39426815e-03]]\n",
      "\n",
      " [[ 9.94133879e-04  1.78845238e-03  5.10488404e-04 ...  1.45209790e-03\n",
      "   -3.51191266e-03  5.19280904e-04]\n",
      "  [ 2.44710129e-04 -3.05099809e-03  2.66723824e-03 ...  5.28692501e-03\n",
      "   -2.07469566e-03  1.96855585e-03]\n",
      "  [-7.03972718e-03 -5.44425379e-03  7.75704393e-04 ...  5.55931963e-03\n",
      "    1.17619359e-03  2.48327386e-03]\n",
      "  ...\n",
      "  [-3.29103880e-03  3.63686215e-03 -6.49655238e-03 ...  1.25757768e-03\n",
      "   -2.95093213e-03  6.23993203e-03]\n",
      "  [-6.26770547e-04  4.20124875e-03 -5.98160690e-03 ...  2.03527138e-03\n",
      "   -5.88213559e-03  4.49904380e-03]\n",
      "  [ 2.32275808e-03 -6.27502566e-04 -1.02034975e-02 ...  1.34113571e-03\n",
      "   -1.46666374e-02 -1.90616550e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 2.52997922e-03 -3.03303264e-03  2.84715462e-03 ...  3.15668224e-03\n",
      "   -4.72390559e-03 -9.01479274e-03]\n",
      "  [ 4.21634642e-03 -4.72375378e-03  4.34555719e-03 ...  5.34156617e-03\n",
      "   -7.25312764e-03 -1.58150271e-02]\n",
      "  [-6.71128742e-04 -4.17693099e-03 -3.98897799e-03 ...  6.98453980e-04\n",
      "   -1.68979634e-03 -1.48662739e-02]\n",
      "  ...\n",
      "  [ 4.89271060e-03 -9.12959222e-04 -5.65832201e-03 ...  3.76463751e-03\n",
      "   -6.49057655e-03  4.79327515e-03]\n",
      "  [ 3.99659434e-03 -9.66087217e-04 -7.45359436e-03 ...  2.97870580e-03\n",
      "   -8.50661006e-03  8.02839117e-04]\n",
      "  [ 4.01606224e-03  6.69088855e-04 -6.18754327e-03 ...  3.38401040e-03\n",
      "   -1.09689515e-02  3.14447912e-04]]\n",
      "\n",
      " [[ 2.58576940e-03  2.90157762e-03 -2.07857229e-05 ...  9.39412392e-04\n",
      "   -3.05658788e-03 -3.97756055e-04]\n",
      "  [ 7.37589202e-04  2.12287786e-03 -1.13106798e-03 ...  6.24662545e-03\n",
      "   -9.60652949e-04  3.02749686e-06]\n",
      "  [-2.83940486e-03  3.22634447e-03 -2.99092592e-03 ...  4.28067520e-03\n",
      "    2.19674734e-03  4.05347906e-04]\n",
      "  ...\n",
      "  [ 3.01692169e-04  2.11798307e-03  4.71878983e-03 ...  2.04281881e-04\n",
      "   -4.78372909e-03  2.67240452e-04]\n",
      "  [ 1.79344509e-03  5.01396041e-03  7.63776619e-03 ... -3.29449284e-03\n",
      "    9.32207331e-05  5.75501472e-03]\n",
      "  [ 1.11448253e-03  4.92644683e-03  1.21396845e-02 ... -4.89286613e-03\n",
      "    4.98109590e-03  5.99312643e-03]]\n",
      "\n",
      " [[-4.61240811e-03  1.63966487e-03 -1.05109706e-03 ...  2.60368688e-05\n",
      "    4.04567830e-03 -2.53483769e-04]\n",
      "  [-2.61215749e-03  6.29420625e-04 -2.44933041e-03 ...  5.87821938e-04\n",
      "    9.06836009e-04 -2.30057864e-03]\n",
      "  [-2.50393921e-03  5.45615144e-03 -3.59387044e-03 ...  4.34117252e-03\n",
      "    1.06085476e-03  6.61450089e-04]\n",
      "  ...\n",
      "  [ 3.56691703e-03 -1.18554467e-02  7.79565144e-03 ...  4.45690472e-03\n",
      "    4.89486428e-03  1.44630894e-02]\n",
      "  [ 5.18682599e-03 -1.20776407e-02  8.50659609e-03 ...  2.94126384e-03\n",
      "    7.78605882e-03  1.53136961e-02]\n",
      "  [-5.27715310e-05 -6.53262297e-03  5.92978671e-03 ... -3.72711103e-04\n",
      "    3.98811093e-03  1.06755579e-02]]], shape=(64, 100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(len(example_batch_prediction))\n",
    "print(example_batch_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c84add8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tf.Tensor(\n",
      "[[-4.6124081e-03  1.6396649e-03 -1.0510971e-03 ...  2.6036869e-05\n",
      "   4.0456783e-03 -2.5348377e-04]\n",
      " [-3.9437232e-03  6.3474225e-03 -2.3598068e-03 ...  4.1175969e-03\n",
      "   3.9276588e-03  2.6906091e-03]\n",
      " [-5.0084922e-04  7.0459764e-03 -2.4984297e-03 ...  3.6820085e-03\n",
      "   6.2471617e-04  1.8557366e-03]\n",
      " ...\n",
      " [ 6.1543658e-05 -2.2276498e-04 -2.2692382e-03 ...  3.2537794e-03\n",
      "  -1.6313205e-03 -2.1682626e-03]\n",
      " [ 4.5498773e-03  2.5771505e-03 -9.4888825e-04 ...  4.3889377e-03\n",
      "  -4.4668722e-03 -3.3291481e-03]\n",
      " [ 1.3749814e-04  4.3157632e-03 -8.9892198e-04 ...  4.0055066e-03\n",
      "   2.7971715e-04 -2.8496564e-03]], shape=(100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pred = example_batch_prediction[0]\n",
    "print(len(pred))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db9e32ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "tf.Tensor(\n",
      "[-4.6124081e-03  1.6396649e-03 -1.0510971e-03 -1.5650725e-04\n",
      " -3.3166262e-03 -9.0640126e-04 -4.2850757e-03 -3.2226468e-05\n",
      "  6.1755901e-04 -4.4053519e-04  3.2433384e-04 -3.4911418e-03\n",
      "  7.7201463e-03  3.4157098e-03  5.5186269e-03 -9.7741373e-05\n",
      " -3.8897966e-03 -3.5258872e-03  1.4725479e-03  1.5224860e-03\n",
      "  2.5860462e-03 -1.9491153e-03 -2.7618646e-03 -5.4274793e-03\n",
      "  3.7451603e-03 -3.7883647e-04  5.1989034e-04 -3.3908235e-03\n",
      " -1.8078517e-03  1.4428380e-03  5.0310940e-03 -5.7438028e-04\n",
      " -3.7095330e-03  2.8856453e-03  1.1415258e-03  3.3774534e-03\n",
      "  3.4724805e-03  2.3394046e-04 -2.1370919e-03  2.4270252e-03\n",
      " -2.2422615e-03  5.5239582e-03  3.8640413e-03  4.5099999e-03\n",
      " -8.3406165e-04  1.3464985e-03  3.4763146e-04 -8.5753680e-04\n",
      "  5.7834345e-03 -3.3733258e-03  1.3560931e-03  6.2963821e-04\n",
      " -3.6314065e-03  1.4660950e-04  1.8513033e-03 -3.5593184e-03\n",
      " -4.4179778e-03  5.9663528e-04  3.1463001e-03 -3.6286127e-03\n",
      "  4.6372376e-04 -4.0848460e-04  2.6036869e-05  4.0456783e-03\n",
      " -2.5348377e-04], shape=(65,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "time_pred = pred[0]\n",
    "print(len(time_pred))\n",
    "print(time_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70da6910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"blDTW$in'e,,DpglOfCLXlfcz;bU3baBmxlvSTRNTgYvEEGn!$3stmOXWcp-n;ZdMYTUghjtN3cNlP\\nSsY!\\nScE&kVbDkJDz,RHv\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
    "\n",
    "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
    "prediction_chars = int_to_text(sampled_indices)\n",
    "\n",
    "prediction_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94f6e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6aad32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022b8a5a",
   "metadata": {},
   "source": [
    "Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f32fd92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"./training_checkpoints\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f7ac5",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa8514ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 827ms/step - loss: 2.4070\n",
      "Epoch 2/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 828ms/step - loss: 1.7749\n",
      "Epoch 3/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 829ms/step - loss: 1.5656\n",
      "Epoch 4/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 793ms/step - loss: 1.4594\n",
      "Epoch 5/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 803ms/step - loss: 1.3934\n",
      "Epoch 6/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 843ms/step - loss: 1.3460\n",
      "Epoch 7/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 816ms/step - loss: 1.3071\n",
      "Epoch 8/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 836ms/step - loss: 1.2713\n",
      "Epoch 9/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 794ms/step - loss: 1.2402\n",
      "Epoch 10/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 824ms/step - loss: 1.2091\n",
      "Epoch 11/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 803ms/step - loss: 1.1776\n",
      "Epoch 12/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 801ms/step - loss: 1.1458\n",
      "Epoch 13/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 801ms/step - loss: 1.1130\n",
      "Epoch 14/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 841ms/step - loss: 1.0797\n",
      "Epoch 15/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 801ms/step - loss: 1.0464\n",
      "Epoch 16/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 842ms/step - loss: 1.0107\n",
      "Epoch 17/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 807ms/step - loss: 0.9741\n",
      "Epoch 18/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 821ms/step - loss: 0.9394\n",
      "Epoch 19/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 807ms/step - loss: 0.9021\n",
      "Epoch 20/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 802ms/step - loss: 0.8678\n",
      "Epoch 21/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 816ms/step - loss: 0.8340\n",
      "Epoch 22/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 849ms/step - loss: 0.8003\n",
      "Epoch 23/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 789ms/step - loss: 0.7692\n",
      "Epoch 24/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 784ms/step - loss: 0.7390\n",
      "Epoch 25/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 789ms/step - loss: 0.7115\n",
      "Epoch 26/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 793ms/step - loss: 0.6862\n",
      "Epoch 27/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 791ms/step - loss: 0.6607\n",
      "Epoch 28/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 791ms/step - loss: 0.6392\n",
      "Epoch 29/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 791ms/step - loss: 0.6175\n",
      "Epoch 30/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 790ms/step - loss: 0.5997\n",
      "Epoch 31/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 794ms/step - loss: 0.5825\n",
      "Epoch 32/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 798ms/step - loss: 0.5669\n",
      "Epoch 33/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 795ms/step - loss: 0.5525\n",
      "Epoch 34/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 791ms/step - loss: 0.5391\n",
      "Epoch 35/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 787ms/step - loss: 0.5270\n",
      "Epoch 36/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 785ms/step - loss: 0.5164\n",
      "Epoch 37/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 791ms/step - loss: 0.5056\n",
      "Epoch 38/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 788ms/step - loss: 0.4973\n",
      "Epoch 39/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 786ms/step - loss: 0.4874\n",
      "Epoch 40/40\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 789ms/step - loss: 0.4822\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data, epochs=40, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07bea106",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33e479c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./training_checkpoints/ckpt_10.weights.h5')\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ad43f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 800\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 1.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "    \n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the character returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted character as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f25c95c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'reset_states'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m inp = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mType a starting string: \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mgenerate_text\u001b[39m\u001b[34m(model, start_string)\u001b[39m\n\u001b[32m     17\u001b[39m temperature = \u001b[32m1.0\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Here batch size == 1\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset_states\u001b[49m()\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_generate):\n\u001b[32m     22\u001b[39m     predictions = model(input_eval)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Functional' object has no attribute 'reset_states'"
     ]
    }
   ],
   "source": [
    "inp = input(\"Type a starting string: \")\n",
    "print(generate_text(model, inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87afdcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
